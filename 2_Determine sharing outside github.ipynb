{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define article restrictions\n",
    "journals_keep = ['Nat Commun', 'Nat Neurosci', 'Nat Methods',\n",
    "                 'PLoS One',\n",
    "                 'PLoS Comput Biol', 'Proc Natl Acad Sci U S A']\n",
    "cols_keep = ['Journal Title', 'Year', 'PMCID', 'PMID']\n",
    "year_min = 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scott/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (4,5,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load database of available articles\n",
    "df = pd.read_csv('/gh/data/opencode/PMC-ids.csv')\n",
    "\n",
    "df_keep = df[(df['Journal Title'].isin(journals_keep)) &\n",
    "             (df['Year'] >= year_min)\n",
    "             ]\n",
    "df_keep = df_keep[cols_keep]\n",
    "\n",
    "# Remove articles without a PMID (not read)\n",
    "df_keep.dropna(subset=['PMID'], inplace=True)\n",
    "df_keep = df_keep.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load information scraped from the articles\n",
    "N_articles = 147359\n",
    "N_chunk = 10000\n",
    "file_nums = np.append(np.arange(N_chunk, N_articles, N_chunk), N_articles)\n",
    "# terms = ['python', 'matlab', 'public', 'open', 'code', 'source', 'github']\n",
    "terms = ['python', 'matlab', 'open', 'code', 'github']\n",
    "other = ['aff', 'subject']\n",
    "\n",
    "dfs = defaultdict(list)\n",
    "for k in terms + other:\n",
    "    for fi_num in file_nums:\n",
    "        csv_name = '/gh/data2/opencode/june29/{:s}_{:d}.csv'.format(k, fi_num)\n",
    "        dfs[k].append(pd.read_csv(csv_name, index_col=0))\n",
    "    dfs[k] = pd.concat(dfs[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only keep articles with MATLAB or python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_mat = dfs['matlab']['PMCID'].unique()\n",
    "ids_py = dfs['python']['PMCID'].unique()\n",
    "ids_code = np.union1d(ids_mat, ids_py)\n",
    "dfs_code = {}\n",
    "for k in dfs.keys():\n",
    "    dfs_code[k] = dfs[k][dfs[k]['PMCID'].isin(ids_code)]\n",
    "    \n",
    "df_articles = df_keep[df_keep['PMCID'].isin(ids_code)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify each article from a journal as sharing or not\n",
    "\n",
    "Input:\n",
    "* y = shared code\n",
    "* n = undetermined\n",
    "* s = skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define journal and categories of interest\n",
    "# journal = 'Proc Natl Acad Sci U S A'\n",
    "journal = 'Nat Methods'\n",
    "# Note previous order for PNAS was ['github', 'code', 'python', 'matlab', 'open']\n",
    "category_order = ['github', 'python', 'matlab', 'code', 'open']\n",
    "\n",
    "# Define articles of interest\n",
    "article_ids = df_articles[df_articles['Journal Title']==journal]['PMCID'].values\n",
    "\n",
    "# If the file already exists, then load it and skip the article ids covered\n",
    "if os.path.isfile('labels/'+journal+'.csv'):\n",
    "    df_old = pd.read_csv('labels/'+journal+'.csv')\n",
    "    dict_class = {}\n",
    "    for col in df_old.columns:\n",
    "        dict_class[col] = list(df_old[col])\n",
    "    article_ids = np.setdiff1d(article_ids, df_old['PMCID'].unique())\n",
    "else:\n",
    "    dict_class = defaultdict(list)\n",
    "\n",
    "# Print 1 category and 1 sentence at a time\n",
    "for i_article, aid in enumerate(article_ids):\n",
    "    classified = False\n",
    "    for cat in category_order:\n",
    "        all_sentences = dfs_code[cat][dfs_code[cat]['PMCID']==aid]['sentence'].values\n",
    "        for i_sent, sent in enumerate(all_sentences):\n",
    "            # Prompt user\n",
    "            start_time = time()\n",
    "            print('Sentence {:d}/{:d}\\nCategory: {:s}\\nArticle {:d}/{:d}, id {:s}'.format(\n",
    "                i_sent+1, len(all_sentences), cat, i_article+1, len(article_ids), aid))\n",
    "            ans = input(sent)\n",
    "            clear_output()\n",
    "            \n",
    "            # Save default output\n",
    "            dict_class['PMCID'].append(aid)\n",
    "            dict_class['category'].append(cat)\n",
    "            dict_class['sentence'].append(i_sent)\n",
    "            dict_class['label'].append(ans)\n",
    "            dict_class['time_ms'].append(int((time()-start_time)*1000))\n",
    "            \n",
    "            if ans == 'y':\n",
    "                classified = True\n",
    "                break\n",
    "            elif ans == 'q':\n",
    "                raise ValueError('Quit by user.')\n",
    "            elif ans != 'n':\n",
    "                raise ValueError('Invalid answer: {:s}'.format(ans))\n",
    "                \n",
    "        if classified:\n",
    "            break\n",
    "    \n",
    "    # Save classification\n",
    "    pd.DataFrame(dict_class).to_csv('labels/'+journal+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharing findings for PNAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/95 articles contain \"github\"\n",
      "25/95 articles share code\n",
      "17/17 \"github\" articles share code\n",
      "^NOTE: Some of those were not identified by the \"github\" link\n",
      "Conclude: We underestimate code sharing by ~1/3 when just looking for the github string\n"
     ]
    }
   ],
   "source": [
    "# Load manually labeled sharing\n",
    "journal = 'Proc Natl Acad Sci U S A'\n",
    "df_labeled = pd.read_csv('labels/'+journal+'.csv')\n",
    "ids_share_labeled = df_labeled[df_labeled['label']=='y']['PMCID'].values\n",
    "\n",
    "# Load articles containing 'github'\n",
    "df_pnas = df_articles[df_articles['Journal Title']==journal]\n",
    "ids_pnas = df_pnas['PMCID']\n",
    "ids_github = dfs['github']['PMCID'].unique()\n",
    "df_github = df_pnas[df_pnas['PMCID'].isin(ids_github)]\n",
    "ids_share_github = df_github['PMCID'].values\n",
    "\n",
    "print('{:d}/{:d} articles contain \"github\"'.format(len(ids_share_github), len(ids_pnas)))\n",
    "print('{:d}/{:d} articles share code'.format(len(ids_share_labeled), len(ids_pnas)))\n",
    "\n",
    "\n",
    "print('{:d}/{:d} \"github\" articles share code'.format(len(np.intersect1d(ids_share_github, ids_share_labeled)), len(ids_share_github)))\n",
    "print('^NOTE: Some of those were not identified by the \"github\" link\\nConclude: We underestimate code sharing by ~1/3 when just looking for the github string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharing findings for Nat Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/105 articles contain \"github\"\n",
      "56/105 articles share code\n",
      "35/36 \"github\" articles share code\n",
      "^NOTE: Some of those were not identified by the \"github\" link\n",
      "Conclude: We underestimate code sharing by ~1/3 when just looking for the github string\n"
     ]
    }
   ],
   "source": [
    "# Load manually labeled sharing\n",
    "journal = 'Nat Methods'\n",
    "df_labeled = pd.read_csv('labels/'+journal+'.csv')\n",
    "ids_share_labeled = df_labeled[df_labeled['label']=='y']['PMCID'].values\n",
    "\n",
    "# Load articles containing 'github'\n",
    "df_pnas = df_articles[df_articles['Journal Title']==journal]\n",
    "ids_pnas = df_pnas['PMCID']\n",
    "ids_github = dfs['github']['PMCID'].unique()\n",
    "df_github = df_pnas[df_pnas['PMCID'].isin(ids_github)]\n",
    "ids_share_github = df_github['PMCID'].values\n",
    "\n",
    "print('{:d}/{:d} articles contain \"github\"'.format(len(ids_share_github), len(ids_pnas)))\n",
    "print('{:d}/{:d} articles share code'.format(len(ids_share_labeled), len(ids_pnas)))\n",
    "\n",
    "\n",
    "print('{:d}/{:d} \"github\" articles share code'.format(len(np.intersect1d(ids_share_github, ids_share_labeled)), len(ids_share_github)))\n",
    "print('^NOTE: Some of those were not identified by the \"github\" link\\nConclude: We underestimate code sharing by ~1/3 when just looking for the github string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
